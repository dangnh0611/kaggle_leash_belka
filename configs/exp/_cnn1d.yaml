# @package _global_

defaults:
  - override /task: leash
  - override /data: leash
  - override /criterion: bce
  - override /model: cnn1d
  - _self_

callbacks:
  early_stopping:
    patience: 5 # number of checks with no improvement after which training will be stopped

trainer:
  max_epochs: 30
  gradient_clip_val: null
  precision: 16-mixed
  deterministic: True
  benchmark: False
  log_every_n_steps: 50

loader:
  train_batch_size: 4096
  num_workers: 16

cv:
  strategy: 'skf20'
  num_folds: 20
  fold_idx: 0
  

optim:
  name: torch@adam
  lr: 1e-3
  weight_decay: 0.05
  eps: 1e-7
  # momentum: 0.9

scheduler:
  name: timm@cosine
  warmup_epochs: 0
  cooldown_epochs: 0
  min_lr_factor: 5e-2
  warmup_lr_factor: 1e-3
  cycle_limit: 1
  cycle_decay: 0.5

ema:
  enable: False
  train_decays: [0.99]
  val_decays: [0.99, 0.0]
  test_decays: ${ema.train_decays}
  force_cpu: False
  reset_from: global_best # null or none, primary, last_best, global_best
  reset_sched_epochs: [-1] # list of epochs to perform reset
  reset_on_plateau: -1

viz:
  enable: False
  train_batch: 1
  val_batch: 1
  bs_limit: 8
  dpi: 200

seed: 42

logger:
  wandb:
    project: leash

exp_name: baseline
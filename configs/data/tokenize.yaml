_target_: src.data.datasets.base.BaseDataModule
_dataset_target_: src.data.datasets.tokenize.TokenizeDataset

ram_cache: False

tokenizer:
  name: smiles_char
  padding: longest
  max_length: 2048
  is_split_into_words: False
  pad_to_multiple_of: null

subsample: null
sample_weights: null

isomeric: True
kekulize: False
replace_dy: False
do_random: 0.0
template: '[CLS]{0}'





